# Project Vimaan - Changelog

All notable changes to this project will be documented in this file.

---

### Version: 0.5.0
**ID:** 961717b
**Date:** 2025-10-12
**Module:** Machine Learning - Model Training & Inference
**Author:** Mohammad Hasnain Raza

#### Description of Change:
- **Added Model Training Pipeline**: Created the core `train_nlu_model.py` script to train a joint intent-and-slot NLU model using DistilBERT.
- **Implemented Validation & Early Stopping**: Upgraded the training script to include a validation loop to monitor performance on unseen data and an early stopping mechanism to prevent overfitting and automatically save the best model.
- **Created Inference Script**: Developed `predict.py` to load the trained model and provide an interactive command-line interface for real-time testing and performance evaluation.
- **Automated Workflow**: Made the training and prediction scripts version-aware, enabling them to automatically find the latest dataset and model versions.

#### Enhancement Over Previous Version (v0.4.x):
- **Core AI Capability**: This update introduces the "brain" of Project Vimaan, transitioning the project from data preparation to a functional, trained NLU model.
- **Professional Training Workflow**: The addition of a validation loop and early stopping represents a shift to a robust, industry-standard training process that produces more reliable models.
- **Complete Feedback Loop**: With the `predict.py` script, a full development cycle is now in place: `Data Generation -> Training -> Interactive Testing`.

---

### Version: 0.4.0
**ID:** a371380
**Date:** 2025-10-06
**Module:** Machine Learning - Data Generation
**Author:** Mohammad Hasnain Raza

#### Description of Change:
- **Refactored Data Pipeline**: Overhauled the entire data generation workflow for better organization and scalability.
- **Introduced Folder Structure**: All scripts now read from and write to a structured `datasets/` directory with subfolders for each stage of the pipeline (e.g., `01_base`, `02_augmented_...`, etc.).
- **Implemented Auto-Versioning**: All data creation scripts now use a helper function in `utils.py` to automatically save outputs to new, versioned files (e.g., `..._v1.jsonl`, `..._v2.jsonl`).
- **Enhanced Verification Logic**: Updated `verify_dataset.py` to intelligently check for both digits and their word equivalents (e.g., "20" or "twenty"), improving the accuracy of data quality checks.

#### Enhancement Over Previous Version (v0.3.x):
- **Organization & Scalability**: The new folder structure makes the project significantly cleaner and easier to manage as more experiments are added.
- **Reproducibility & Experiment Tracking**: The versioning system prevents accidental data overwrites and creates a clear, traceable history of every dataset generated.
- **Improved Data Quality**: The smarter verification ensures that semantically correct but differently formatted data is not incorrectly flagged as an error.

---
### Version: 0.3.0
**ID:** 777f435
**Date:** 2025-10-05
**Module:** Machine Learning - Data Generation
**Author:** Mohammad Hasnain Raza

#### Description of Change:
- **Upgraded Data Generation Pipeline**: This commit includes a series of major enhancements to the data generation process.
- **Dynamic Frequency Generation**: Modified `generate_slot_dataset.py` to create a unique, random COM frequency for every example, significantly increasing data diversity.
- **AI-Powered Augmentation**: Introduced a new script, `augment_with_paraphrasing.py`, which uses a pre-trained Pegasus model (`tuner007/pegasus_paraphrase`) to generate multiple linguistic variations of each command.
- **Path-Aware Scripts**: Both scripts were updated to be path-aware, ensuring they can be run reliably regardless of the terminal's working directory.

#### Enhancement Over Previous Version (v0.2.x):
- **Greatly Increased Robustness**: The combination of dynamic slot generation and AI-powered paraphrasing creates a dataset that is vastly more diverse and representative of real-world language, which is critical for training a commercial-grade model.
- **Improved Workflow**: The data pipeline is now more resilient to common path and dependency issues, making the development process smoother.

---

### Version: 0.2.1
**ID:** 2090c6f
**Date:** 2025-10-04
**Module:** Machine Learning - Data Generation
**Author:** Mohammad Hasnain Raza

#### Description of Change:
- Created a new script, `augment_with_paraphrasing.py`, that uses a pre-trained T5 transformer model to paraphrase and augment the existing dataset.
- The script loads the dataset generated by `generate_slot_dataset.py`, generates multiple unique rephrasings for each command, and creates new data points while preserving the original intent and slot values.

#### Enhancement Over Previous Version (v0.2.0):
- **Addresses Dataset Brittleness**: This directly solves the limitation of the template-based approach. By generating AI-powered paraphrases, the dataset becomes far more diverse and less predictable, better reflecting the variability of human language.
- **Improved Model Robustness**: Training on this augmented data will force the NLU model to learn the underlying semantic meaning of commands rather than simply memorizing sentence structures.

---

### Version: 0.2.0
**ID:** 2090c6f
**Date:** 2025-10-04
**Module:** Machine Learning - Data Generation
**Author:** Mohammad Hasnain Raza

#### Description of Change:
- Redesigned the data generation script (`generate_slot_dataset.py`) to support joint intent classification and slot filling.
- Implemented a centralized, schema-driven architecture where intents are defined with associated slots (e.g., `degrees`, `altitude`), templates, and realistic value sets.
- The output format is now a structured JSONL file containing distinct `text`, `intent`, and `slots` fields.

#### Enhancement Over Previous Version (v0.1.0):
- **Architectural Leap**: This update transitions the NLU task from simple intent classification to a more advanced structured information extraction model.
- **Expanded Capability**: The system is no longer limited to boolean (on/off) commands. It can now be trained to understand and extract parameters/values from pilot commands.
- **Scalability**: The new schema makes it significantly easier to add new, complex commands in the future without major code rewrites. 