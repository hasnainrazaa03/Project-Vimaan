# Project Vimaan - Changelog

All notable changes to this project will be documented in this file.

---

### Version: 0.4.0
**ID:** a371380
**Date:** 2025-10-06
**Module:** Machine Learning - Data Generation
**Author:** Mohammad Hasnain Raza

#### Description of Change:
- **Refactored Data Pipeline**: Overhauled the entire data generation workflow for better organization and scalability.
- **Introduced Folder Structure**: All scripts now read from and write to a structured `datasets/` directory with subfolders for each stage of the pipeline (e.g., `01_base`, `02_augmented_...`, etc.).
- **Implemented Auto-Versioning**: All data creation scripts now use a helper function in `utils.py` to automatically save outputs to new, versioned files (e.g., `..._v1.jsonl`, `..._v2.jsonl`).
- **Enhanced Verification Logic**: Updated `verify_dataset.py` to intelligently check for both digits and their word equivalents (e.g., "20" or "twenty"), improving the accuracy of data quality checks.

#### Enhancement Over Previous Version (v0.3.x):
- **Organization & Scalability**: The new folder structure makes the project significantly cleaner and easier to manage as more experiments are added.
- **Reproducibility & Experiment Tracking**: The versioning system prevents accidental data overwrites and creates a clear, traceable history of every dataset generated.
- **Improved Data Quality**: The smarter verification ensures that semantically correct but differently formatted data is not incorrectly flagged as an error.

---
### Version: 0.3.0
**ID:** 777f435
**Date:** 2025-10-05
**Module:** Machine Learning - Data Generation
**Author:** Mohammad Hasnain Raza

#### Description of Change:
- **Upgraded Data Generation Pipeline**: This commit includes a series of major enhancements to the data generation process.
- **Dynamic Frequency Generation**: Modified `generate_slot_dataset.py` to create a unique, random COM frequency for every example, significantly increasing data diversity.
- **AI-Powered Augmentation**: Introduced a new script, `augment_with_paraphrasing.py`, which uses a pre-trained Pegasus model (`tuner007/pegasus_paraphrase`) to generate multiple linguistic variations of each command.
- **Path-Aware Scripts**: Both scripts were updated to be path-aware, ensuring they can be run reliably regardless of the terminal's working directory.

#### Enhancement Over Previous Version (v0.2.x):
- **Greatly Increased Robustness**: The combination of dynamic slot generation and AI-powered paraphrasing creates a dataset that is vastly more diverse and representative of real-world language, which is critical for training a commercial-grade model.
- **Improved Workflow**: The data pipeline is now more resilient to common path and dependency issues, making the development process smoother.

---

### Version: 0.2.1
**ID:** 2090c6f
**Date:** 2025-10-04
**Module:** Machine Learning - Data Generation
**Author:** Mohammad Hasnain Raza

#### Description of Change:
- Created a new script, `augment_with_paraphrasing.py`, that uses a pre-trained T5 transformer model to paraphrase and augment the existing dataset.
- The script loads the dataset generated by `generate_slot_dataset.py`, generates multiple unique rephrasings for each command, and creates new data points while preserving the original intent and slot values.

#### Enhancement Over Previous Version (v0.2.0):
- **Addresses Dataset Brittleness**: This directly solves the limitation of the template-based approach. By generating AI-powered paraphrases, the dataset becomes far more diverse and less predictable, better reflecting the variability of human language.
- **Improved Model Robustness**: Training on this augmented data will force the NLU model to learn the underlying semantic meaning of commands rather than simply memorizing sentence structures.

---

### Version: 0.2.0
**ID:** 2090c6f
**Date:** 2025-10-04
**Module:** Machine Learning - Data Generation
**Author:** Mohammad Hasnain Raza

#### Description of Change:
- Redesigned the data generation script (`generate_slot_dataset.py`) to support joint intent classification and slot filling.
- Implemented a centralized, schema-driven architecture where intents are defined with associated slots (e.g., `degrees`, `altitude`), templates, and realistic value sets.
- The output format is now a structured JSONL file containing distinct `text`, `intent`, and `slots` fields.

#### Enhancement Over Previous Version (v0.1.0):
- **Architectural Leap**: This update transitions the NLU task from simple intent classification to a more advanced structured information extraction model.
- **Expanded Capability**: The system is no longer limited to boolean (on/off) commands. It can now be trained to understand and extract parameters/values from pilot commands.
- **Scalability**: The new schema makes it significantly easier to add new, complex commands in the future without major code rewrites. 